{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_imgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f560cfbd16cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# max_val,max_loc,templates[i].shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# 设置初始化窗口\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_imgs' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    " \n",
    "cap = cv2.VideoCapture('002_RI_full.mp4')\n",
    "\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 获取视频第一帧\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# max_val,max_loc,templates[i].shape\n",
    "first=frame.copy()\n",
    "info = get_imgs(first)\n",
    "\n",
    "# 设置初始化窗口\n",
    "r, h, c, w = 250, 90, 400, 125\n",
    "track_window = (c, r, w, h)\n",
    "# 设置跟踪的ROI区域\n",
    "roi = frame[r: r + h, c: c + w]\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "mask  = cv2.inRange(hsv_roi, np.array((0., 60., 32.)), np.array((180., 255., 255.)))\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
    "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "# 设置终止条件，迭代10次或移动1pt\n",
    "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)\n",
    "\n",
    "\n",
    "ret, frame = cap.read()\n",
    "if ret:\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "    # 使用meanShift获得新位置\n",
    "    ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "    pts = cv2.boxPoints(ret)\n",
    "    pts = np.int0(pts)\n",
    "    print('len pts:', len(pts), pts)\n",
    "    img2 = cv2.polylines(frame, [pts], True,(255, 0, 0), 2)\n",
    "    cv2.imshow('img2', img2)\n",
    "    k = cv2.waitKey(int(1000/ fps))  # & 0xff\n",
    "        \n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp1=cv2.imread(\"C:/Users/Luka/Desktop/585-hw2/template-flat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_1.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_2.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_3.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_4.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_5.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_6.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_7.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_8.png\n",
      "C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs/LAS_9.png\n"
     ]
    }
   ],
   "source": [
    "temp_path = r'C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs'\n",
    "for i in range(1,10):\n",
    "    print(temp_path+\"/\"+\"LAS\"+\"_\"+str(i)+\".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"w\",cv2.imread(temp_path+\"/\"+\"LAS\"+\"_\"+str(9)+\".png\",0))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_imgs(org,thr=None,opt=None):\n",
    "    if not thr:\n",
    "        thr = 0.6\n",
    "    if not opt:\n",
    "        opt = 1\n",
    "    templates = []\n",
    "    temp_path = r'C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs'\n",
    "    for i in range(1,10):\n",
    "        templates.append(cv2.imread(temp_path+\"/\"+\"LAS\"+\"_\"+str(i)+\".png\",0))####GRAYSCALE\n",
    "    w, h = [template.shape[::-1][0] for template in templates], [template.shape[::-1][1] for template in templates]\n",
    "    \n",
    "    res_list=[]\n",
    "    \n",
    "    methods = ['cv2.TM_CCOEFF_NORMED']\n",
    "\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        img = org.copy()\n",
    "        VL=[]\n",
    "        for i in range(len(templates)):\n",
    "            \n",
    "            res = cv2.matchTemplate(img, templates[i], method)\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "            if max_loc[1] < org.shape[0]*0.2:\n",
    "                VL.append([max_val,max_loc,i])\n",
    "        VL.sort(key=lambda x:-x[0])\n",
    "\n",
    "        for i in range(opt):\n",
    "            if VL[i][0]>thr:\n",
    "                top_left = VL[i][1]\n",
    "                bottom_right = (top_left[0] + w[VL[i][2]], top_left[1] + h[VL[i][2]])\n",
    "                cv2.rectangle(img, top_left, bottom_right, 255, 1)\n",
    "                cv2.putText(img,\"template\"+str(VL[i][2]+1)+\"Value=\"+str(VL[i][0])[:4],(top_left[0],top_left[1]), cv2.FONT_HERSHEY_SIMPLEX, 1, 255, 1)\n",
    "#             else:\n",
    "#                 print(\"not draw\")\n",
    "    return VL[0],img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay=int(1000/fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "temp_path = r'C:\\Users\\Luka\\Desktop\\Template\\LAS\\ribs'\n",
    "for i in range(1,10):\n",
    "    templates.append(cv2.imread(temp_path+\"/\"+\"LAS\"+\"_\"+str(i)+\".png\",0))####GRAYSCALE\n",
    "w, h = [template.shape[::-1][0] for template in templates], [template.shape[::-1][1] for template in templates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "video = cv2.VideoCapture('002_RI_full.mp4')\n",
    "\n",
    "size = (int(video.get(cv2.CAP_PROP_FRAME_WIDTH)), int(video.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "delay=int(1000/fps)\n",
    "\n",
    "lb=0\n",
    "rb=size[0]\n",
    "depth=0\n",
    "thr=0.9\n",
    "\n",
    "success, frame = video.read()\n",
    "info,img = get_imgs(frame[:,:,0],thr=thr)# max_val,max_loc,i\n",
    "index=1\n",
    "\n",
    "while(info[0]<thr and success):\n",
    "    success, frame = video.read()\n",
    "    index+=1\n",
    "    if index%5==0:\n",
    "        info,img = get_imgs(frame[:,:,0],thr=thr)\n",
    "        \n",
    "top_left,i=info[1],info[2]\n",
    "\n",
    "roi=frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i]].copy()\n",
    "print(\"ok\")\n",
    "# cv2.imshow(\"s\",img)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# ####get the template\n",
    "# trackwindow=frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i],0].copy()\n",
    "# cv2.imshow(\"s\",trackwindow)\n",
    "# cv2.waitKey(0)\n",
    "\n",
    "# cv2.destroyAllWindows()\n",
    "# video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest=[]\n",
    "while success:\n",
    "    success,frame = video.read()\n",
    "    index+=1\n",
    "    if index%5==0:\n",
    "        rest.append(frame.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-ce5f9478a182>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtop_left\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mroi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtop_left\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ok\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "top_left,i=info[1],info[2]\n",
    "\n",
    "roi=frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i]].copy()\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trackwindow=frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i],0].copy()\n",
    "cv2.imshow(\"tp\",roi)\n",
    "cv2.waitKey(0)\n",
    "cv2.imshow(\"tp\",cv2.resize(roi,(540,200)))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(134, 225)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_window = (top_left[1],top_left[0],w[i],h[i])\n",
    "\n",
    "# 从当前帧中框出一个小框\n",
    "# roi = frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i]]\n",
    "# RGB转为HSV更好处理\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],None,[255],[0,255])\n",
    "\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# 设置迭代的终止标准，最多十次迭代\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "k=0\n",
    "while(k<=len(rest)-1):\n",
    "    frame = rest[k].copy()\n",
    "\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # 反向投影函数（特征提取函数）\n",
    "    # 反向投影是一种记录给定图像中的像素点如何适应直方图模型像素分布的方式\n",
    "    # 反向投影就是首先计算某一特征的直方图模型，然后使用模型去寻找图像中存在的特征\n",
    "    # cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "\n",
    "    # images:待处理的图像，图像格式为uint8或float32\n",
    "    # channels:对应图像需要统计的通道，若是灰度图则为0，彩色图像B、G、R对应0、1、2\n",
    "    # mask:掩膜图像。如果统计整幅图像就设置为None，否则这里传入设计的掩膜图像。\n",
    "    # histSize表示这个直方图分成多少份（即多少个直方柱）\n",
    "    # ranges:像素量化范围，通常为0 - 255。\n",
    "    dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,255],1)\n",
    "\n",
    "    # RotatedRect CamShift(InputArray probImage, Rect&window, TermCriteria criteria)。\n",
    "    # probImage为输入图像直方图的反向投影图，\n",
    "    # window为要跟踪目标的初始位置矩形框，\n",
    "    # criteria为算法结束条件。\n",
    "    # 函数返回一个有方向角度的矩阵。\n",
    "    #\n",
    "    ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
    "\n",
    "    # 在图片上绘制\n",
    "    x, y, wp, hp = track_window\n",
    "    img2 = cv2.rectangle(frame, (x, y), (x + wp, y + hp), 255, 2)\n",
    "    cv2.imshow('img2', img2)\n",
    "    cv2.waitKey(delay*5) & 0xff\n",
    "    k+=1\n",
    "\n",
    "#     cv2.waitKey(delay) & 0xff\n",
    "            \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackwindow=frame[top_left[1]:top_left[1]+h[i],top_left[0]:top_left[0]+w[i],0].copy()\n",
    "cv2.imshow(\"s\",trackwindow)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi = cv2.imread(\"./gestures/1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158, 219, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e013136bc787>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mroi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./gestures/1.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m# RGB转为HSV更好处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m \u001b[0mhsv_roi\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2HSV\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# inRange函数设置亮度阈值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-oduouqig\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# ret判断是否读到图片\n",
    "# frame读取到的当前帧的矩阵\n",
    "# 返回的是元组类型，所以也可以加括号\n",
    "ret, frame = cap.read()\n",
    "# print(type(ret), ret)\n",
    "# print(type(frame), frame)\n",
    "\n",
    "# print(frame.shape)\n",
    "# # 设置跟踪框参数\n",
    "# r,h,c,w = 250,50,250,50  # simply hardcoded the values\n",
    "# track_window = (c,r,w,h)\n",
    "\n",
    "# # 从当前帧中框出一个小框\n",
    "# roi = frame[r:r+h, c:c+w]\n",
    "roi = cv2.imread(\"./gestures/1.jpg\")\n",
    "# RGB转为HSV更好处理\n",
    "hsv_roi =  cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# inRange函数设置亮度阈值\n",
    "# 去除低亮度的像素点的影响\n",
    "# eg. mask = cv2.inRange(hsv, lower_red, upper_red)\n",
    "\n",
    "# 将低于和高于阈值的值设为0\n",
    "mask = cv2.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "\n",
    "# 然后得到框中图像的直方图\n",
    "# cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate ]])\n",
    "# mask 即上文的阈值设置\n",
    "# histSize表示这个直方图分成多少份（即多少个直方柱）\n",
    "# range是表示直方图能表示像素值的范围\n",
    "# 返回直方图\n",
    "roi_hist = cv2.calcHist([hsv_roi],[0],mask,[255],[0,255])\n",
    "\n",
    "# 归一化函数cv2.normalize(src[, dst[, alpha[, beta[, norm_type[, dtype[, mask]]]]]])\n",
    "# 返回dst类型\n",
    "# 归一化就是要把需要处理的数据经过处理后（通过某种算法）限制在你需要的一定范围内\n",
    "# src  - 输入数组\n",
    "# dst  - 与src大小相同的输出数组\n",
    "# alpha  - 范围值，   以便在范围归一化的情况下归一化到较低范围边界\n",
    "# beta  - 范围归一化时的上限范围; 它不用于标准规范化\n",
    "# normType  - 规范化类型 这里的NORM_MINMAX是数组的数值被平移或缩放到一个指定的范围，线性归一化。\n",
    "# dtype  - 当为负数时，输出数组与src的类型相同；否则，它具有与src相同的通道数；深度=CV_MAT_DEPTH（dtype）\n",
    "# mask  - 可选的操作掩码。\n",
    "cv2.normalize(roi_hist,roi_hist,0,255,cv2.NORM_MINMAX)\n",
    "\n",
    "# 设置迭代的终止标准，最多十次迭代\n",
    "term_crit = ( cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "while(1):\n",
    "    ret ,frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        # 反向投影函数（特征提取函数）\n",
    "        # 反向投影是一种记录给定图像中的像素点如何适应直方图模型像素分布的方式\n",
    "        # 反向投影就是首先计算某一特征的直方图模型，然后使用模型去寻找图像中存在的特征\n",
    "        # cv2.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n",
    "\n",
    "        # images:待处理的图像，图像格式为uint8或float32\n",
    "        # channels:对应图像需要统计的通道，若是灰度图则为0，彩色图像B、G、R对应0、1、2\n",
    "        # mask:掩膜图像。如果统计整幅图像就设置为None，否则这里传入设计的掩膜图像。\n",
    "        # histSize表示这个直方图分成多少份（即多少个直方柱）\n",
    "        # ranges:像素量化范围，通常为0 - 255。\n",
    "        dst = cv2.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "\n",
    "        # RotatedRect CamShift(InputArray probImage, Rect&window, TermCriteria criteria)。\n",
    "        # probImage为输入图像直方图的反向投影图，\n",
    "        # window为要跟踪目标的初始位置矩形框，\n",
    "        # criteria为算法结束条件。\n",
    "        # 函数返回一个有方向角度的矩阵。\n",
    "        #\n",
    "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
    "\n",
    "        # Draw it on image\n",
    "        pts = cv2.boxPoints(ret)\n",
    "\n",
    "        # 类型转换int0()用于索引的整数(same as C ssize_t; normally either int32 or int64)\n",
    "        pts = np.int0(pts)\n",
    "\n",
    "        # 非填充多边形：polylines()\n",
    "        # cv2.polylines(img, pts, isClosed, color[, thickness[, lineType[, shift]]])\n",
    "        # img – 要画的图片\n",
    "        # pts – 多边形的顶点\n",
    "        # isClosed – 是否闭合线段\n",
    "        # color – 颜色\n",
    "        img2 = cv2.polylines(frame,[pts],True, 255,2)\n",
    "        \n",
    "        cv2.imshow('img2',img2)\n",
    "\n",
    "        # 停止追踪按钮\n",
    "        k = cv2.waitKey(60) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        else:\n",
    "            cv2.imwrite(chr(k)+\".jpg\",img2)\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
